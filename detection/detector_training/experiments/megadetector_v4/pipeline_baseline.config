model {
  faster_rcnn {
    # we continue to use 90 classes so all pretrained detector arm weights can be used
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: "faster_rcnn_inception_resnet_v2"
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        height_stride: 8
        width_stride: 8
        scales: 0.25
        scales: 0.5
        scales: 1.0
        scales: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 1.0
        aspect_ratios: 2.0
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.00999999977648
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.699999988079
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        use_dropout: false
        dropout_keep_probability: 1.0
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.600000023842
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}
train_config {
  batch_size: 1
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.800000011921
      min_area: 0.800000011921
    }
  }
  keep_checkpoint_every_n_hours: 1
  optimizer {
    momentum_optimizer {
      learning_rate {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 10
            learning_rate: 0.0003
          }
        }
      }
      momentum_optimizer_value: 0.899999976158
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_type: "detection"
  load_all_detection_checkpoint_vars: true
  fine_tune_checkpoint: "$AZUREML_DATAREFERENCE_artifacts/mdv4_no_coco/run13_frombaselineexp_step1120k/model.ckpt-1120000"
}
train_input_reader {
  label_map_path: "$AZUREML_DATAREFERENCE_artifacts/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "$AZUREML_DATAREFERENCE_tfrecords/?????????_train-?????-of-?????"
  }
  max_number_of_boxes: 200
}
eval_config {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  num_visualizations: 20
  # we want to see empty images in the mix
  min_score_threshold: 0.0
}
eval_input_reader {
  label_map_path: "$AZUREML_DATAREFERENCE_artifacts/label_map.pbtxt"
  shuffle: true
  num_readers: 1
  tf_record_input_reader {
    input_path: "$AZUREML_DATAREFERENCE_tfrecords/?????????_val__-?????-of-?????"
  }
}
